
#########################################################
# SCRIPT: 03_calculate-similarity.R
# TASK: This script calculates the text similarity using "Soft Cosine" algorithm
#########################################################


# PACKAGES ----------------------------------------------------------------
pacman::p_load(furrr)
pacman::p_load(purrr)
pacman::p_load(dplyr)
pacman::p_load(jiebaR)
pacman::p_load(stringr)
pacman::p_load(text2vec)
pacman::p_load(here)

## Locate the project
i_am("code/03_calculate-similarity.R")


# 1. Prepare Data ---------------------------------------------------------
## Event-relevant HuDongE data
detected_post <- read.csv(file = "processed/detected-post_20230326.csv")
head(detected_post)

## Wordvec data
word_vector <- readRDS(file = "processed/word_vectors16-22.rds")
word_list <- row.names(word_vector)

## Generate VSM
word_segment <- worker(stop_word = "data/baidu_stopwords.txt")
generate_vsm <- function(x, y) {
  x_tokens <- segment(
    code = str_remove_all(x, pattern = "[0-9]"),
    jiebar = word_segment
  )
  y_tokens <- segment(
    code = str_remove_all(y, pattern = "[0-9]"),
    jiebar = word_segment
  )
  
  x_tokens <- x_tokens[x_tokens %in% word_list]
  y_tokens <- y_tokens[y_tokens %in% word_list]
  all_tokens <- unique(c(x_tokens, y_tokens))
  
  x_res <- rep(0, length(all_tokens))
  names(x_res) <- all_tokens
  walk(x_tokens, \(word) {x_res[word] <<- x_res[word] + 1})
  
  y_res <- rep(0, length(all_tokens))
  names(y_res) <- all_tokens
  walk(y_tokens, \(word) {y_res[word] <<- y_res[word] + 1})
  
  res <- list("x" = x_res, "y" = y_res, "all" = all_tokens)
  return(res)
}

generate_vsm(
  x = detected_post$回复内容[15],
  y = detected_post$提问内容[15]
)


# 2. Calculate Similarity -------------------------------------------------
## Soft-cosine similarity algorithm
soft_cosine <- function(x_vec, y_vec, m) {
  numerator <- x_vec %*% m %*% y_vec
  denominator <- sqrt(x_vec %*% m %*% x_vec) * sqrt(y_vec %*% m %*% y_vec)
  numerator / denominator
}

run_compute <- function(x, y) {
  ## Corporate did not reply in some samples, return NaN (NA is not a number)
  if (y == "") {
    return(NaN)
  }
  ## Generate similarity matrix
  res <- generate_vsm(x, y)
  simi_matrix <- sim2(
    x = word_vector[res$all, , drop = FALSE],
    y = word_vector[res$all, , drop = FALSE], 
    method = "cosine", 
    norm = "l2"
  )
  walk(
    .x = seq_len(simi_matrix),
    .f = \(x) {
      simi_matrix[x, ][simi_matrix[x, ] < 0] <<- 0
      simi_matrix[x, ] <<- simi_matrix[x, ] ^ 2
    }
  )
  soft_cosine(res$x, res$y, simi_matrix)
}

## Run in parallel using "furrr" package
######################## Tip ########################
# Strategy can only be set as "multicore" (not "multisession")
# because object "word_segment" generated by jiebaR can not 
# be exported to new sessions, and this requires run in CLI
# on Unix-like systems (not Windows, not RStudio) 
#####################################################
plan(strategy = "multicore", workers = 6)
options(future.rng.onMisuse = "ignore") ## Turn off random seed check

reply_similarity <- future_map2_dbl(
  .x = detected_post$提问内容,
  .y = detected_post$回复内容,
  .f = run_compute
)
summary(reply_similarity)

## Save wordvec as rds file
saveRDS(
  object = reply_similarity, 
  file = "processed/reply_similarity.rds"
)


### EOF
